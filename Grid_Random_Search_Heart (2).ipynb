{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6de154",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbede3",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b1db2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40845005",
   "metadata": {},
   "source": [
    "## Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47da4a",
   "metadata": {},
   "source": [
    "Loading the preprocessed data set is kept in a file - 'preprocessed_heart.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4c04e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "1  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "2  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "3  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "4  56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
      "\n",
      "   slope   ca thal  target  \n",
      "0    2.0  3.0  3.0       2  \n",
      "1    2.0  2.0  7.0       1  \n",
      "2    3.0  0.0  3.0       0  \n",
      "3    1.0  0.0  3.0       0  \n",
      "4    1.0  0.0  3.0       0  \n"
     ]
    }
   ],
   "source": [
    "# Load your data (assuming 'data' is your DataFrame)\n",
    "data = pd.read_csv('preprocessed_heart.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0769c",
   "metadata": {},
   "source": [
    "The above code loads the preprocessed data from the CSV file 'preprocessed_heart.csv' into a new DataFrame called data and then prints the contents of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9f012",
   "metadata": {},
   "source": [
    "## Identify the corelations between the variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04e67d",
   "metadata": {},
   "source": [
    "A correlation matrix is used to show correlation coefficients between variables. Each cell in the table displays the correlation between two variables. The values range from -1 to 1. A value closer to 1 indicates a strong positive correlation, while a value closer to -1 indicates a strong negative correlation. A value close to 0 means little to no correlation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7517d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thalach    -0.415399\n",
      "fbs         0.065937\n",
      "chol        0.070315\n",
      "trestbps    0.159978\n",
      "restecg     0.186769\n",
      "age         0.225809\n",
      "sex         0.226601\n",
      "slope       0.387417\n",
      "exang       0.395996\n",
      "cp          0.405182\n",
      "oldpeak     0.508330\n",
      "target      1.000000\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/l4yk23yx03s6wbmpb0nj_0sw0000gp/T/ipykernel_35229/333194660.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = data.corr()\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = data.corr()\n",
    "print(correlation_matrix['target'].sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98608ac3",
   "metadata": {},
   "source": [
    "This code will print the correlation values of all columns in the dataset concerning the 'target' variable, providing insights into which features are most and least correlated with the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de78796",
   "metadata": {},
   "source": [
    "\n",
    "In order to select features for machine learning models like logistic regression, SVM, and decision trees, it's important to consider the features that have a relatively strong correlation with the target variable. Based on the correlation values you provided (with respect to the 'target' variable):\n",
    "\n",
    "Strong Positive Correlation:\n",
    "\n",
    "oldpeak (0.508330)\n",
    "cp (0.405182)\n",
    "exang (0.395996)\n",
    "slope (0.387417)\n",
    "Moderate Positive Correlation:\n",
    "\n",
    "thalach (-0.415399)\n",
    "Weak Positive Correlation:\n",
    "\n",
    "age (0.225809)\n",
    "sex (0.226601)\n",
    "restecg (0.186769)\n",
    "trestbps (0.159978)\n",
    "Weak Positive/Negative Correlation (close to 0):\n",
    "\n",
    "fbs (0.065937)\n",
    "chol (0.070315)\n",
    "Based on these correlation values, the following features seem to have a relatively stronger correlation with the target variable:\n",
    "\n",
    "oldpeak\n",
    "\n",
    "cp\n",
    "\n",
    "exang\n",
    "\n",
    "slope\n",
    "\n",
    "So considering the above features in order to predict the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d167f",
   "metadata": {},
   "source": [
    "## Select features and target varible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e98a046",
   "metadata": {},
   "source": [
    "Selecting the features and the target variable based on the confusion matrix correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "518eb0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = ['oldpeak', 'cp', 'exang', 'slope']\n",
    "X = data[features]\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045deb26",
   "metadata": {},
   "source": [
    "## Test, train and split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89d62d",
   "metadata": {},
   "source": [
    "In the heart disease data set, a split ratio of 80% for training and 20% for testing was used (test_size=0.2). This means 80% of the data is used for training the model, and 20% is used for testing its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "460c5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede6978",
   "metadata": {},
   "source": [
    "## Standardize the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5b52e",
   "metadata": {},
   "source": [
    "Standardizing features in machine learning to deal with algorithms that are sensitive to the scale of the input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "227ed920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8f956",
   "metadata": {},
   "source": [
    "## Randomized Search for Logistic regression, SVM, Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989114af",
   "metadata": {},
   "source": [
    "The Randomized Search is used here to efficiently explore a subset of the hyperparameter space, finding the best combination for the Logistic Regression, SVM, Decision Tree model. This helps in achieving a well-tuned model without the computational cost of evaluating all possible combinations. The provided code allows you to assess the performance of the optimized model using key metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e71064",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3a241c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search - Logistic Regression:\n",
      "Accuracy: 59.02%\n",
      "Precision: 0.54\n",
      "Recall: 0.59\n",
      "F1-Score: 0.54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Logistic Regression\n",
    "logreg_params = {'C': uniform(0.1, 10)}\n",
    "logreg_random = RandomizedSearchCV(LogisticRegression(), logreg_params, n_iter=100, cv=5, random_state=42)\n",
    "logreg_random.fit(X_train_scaled, y_train)\n",
    "best_logreg_random = logreg_random.best_estimator_\n",
    "logreg_random_pred = best_logreg_random.predict(X_test_scaled)\n",
    "logreg_random_accuracy = accuracy_score(y_test, logreg_random_pred)\n",
    "logreg_random_precision = precision_score(y_test, logreg_random_pred, average='weighted')\n",
    "logreg_random_recall = recall_score(y_test, logreg_random_pred, average='weighted')\n",
    "logreg_random_f1 = f1_score(y_test, logreg_random_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Randomized Search model - Logistic Regression\n",
    "print(\"Randomized Search - Logistic Regression:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(logreg_random_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(logreg_random_precision))\n",
    "print(\"Recall: {:.2f}\".format(logreg_random_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(logreg_random_f1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876164c1",
   "metadata": {},
   "source": [
    "It samples 100 sets of hyperparameters from a specified range, evaluates them using 5-fold cross-validation, selects the best estimator, and computes accuracy, precision, recall, and F1-score on the test data. Results are then printed for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52057b",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc06970",
   "metadata": {},
   "source": [
    "Applying random search for SVM to perform hyper parameter tuning, fit the model and apply scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "110e85a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search - SVM:\n",
      "Accuracy: 55.74%\n",
      "Precision: 0.37\n",
      "Recall: 0.56\n",
      "F1-Score: 0.44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for SVM\n",
    "svm_params = {'C': uniform(0.1, 10), 'gamma': uniform(0.1, 1)}\n",
    "svm_random = RandomizedSearchCV(SVC(), svm_params, n_iter=100, cv=5, random_state=42)\n",
    "svm_random.fit(X_train_scaled, y_train)\n",
    "best_svm_random = svm_random.best_estimator_\n",
    "#best_svm_random_ = svm_random.best_params_\n",
    "\n",
    "#best_svm_random_params = svm_random.best_params_\n",
    "svm_random_pred = best_svm_random.predict(X_test_scaled)\n",
    "svm_random_accuracy = accuracy_score(y_test, svm_random_pred)\n",
    "svm_random_precision = precision_score(y_test, svm_random_pred, average='weighted')\n",
    "svm_random_recall = recall_score(y_test, svm_random_pred, average='weighted')\n",
    "svm_random_f1 = f1_score(y_test, svm_random_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Randomized Search model - SVM\n",
    "print(\"Randomized Search - SVM:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(svm_random_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(svm_random_precision))\n",
    "print(\"Recall: {:.2f}\".format(svm_random_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(svm_random_f1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724706a",
   "metadata": {},
   "source": [
    "The above code snippet employs Randomized Search to optimize hyperparameters for a Support Vector Machine (SVM) classifier. It explores a range of 'C' (regularization parameter) and 'gamma' (kernel coefficient) values, performs 100 iterations with 5-fold cross-validation, selects the best estimator, and evaluates its performance on the test data, displaying accuracy, precision, recall, and F1-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752f38d",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3906629",
   "metadata": {},
   "source": [
    "Applying random search for Decision Tree to perform hyper parameter tuning, fit the model and apply scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cce52c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=100. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search - Decision Tree:\n",
      "Accuracy: 54.10%\n",
      "Precision: 0.35\n",
      "Recall: 0.54\n",
      "F1-Score: 0.42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Randomized Search for Decision Tree\n",
    "dt_params = {'max_depth': [3, 5, 7, 10]}\n",
    "dt_random = RandomizedSearchCV(DecisionTreeClassifier(), dt_params, n_iter=100, cv=5, random_state=42)\n",
    "dt_random.fit(X_train_scaled, y_train)\n",
    "best_dt_random = dt_random.best_estimator_\n",
    "dt_random_pred = best_dt_random.predict(X_test_scaled)\n",
    "dt_random_accuracy = accuracy_score(y_test, dt_random_pred)\n",
    "dt_random_precision = precision_score(y_test, dt_random_pred, average='weighted')\n",
    "dt_random_recall = recall_score(y_test, dt_random_pred, average='weighted')\n",
    "dt_random_f1 = f1_score(y_test, dt_random_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Randomized Search model - Decision Tree\n",
    "print(\"Randomized Search - Decision Tree:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(dt_random_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(dt_random_precision))\n",
    "print(\"Recall: {:.2f}\".format(dt_random_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(dt_random_f1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce0b018",
   "metadata": {},
   "source": [
    "It explores different 'max_depth' values (3, 5, 7, 10) using 100 iterations and 5-fold cross-validation. After fitting the model on the scaled training data, it evaluates the best estimator's performance on the test data, calculating accuracy, precision, recall, and F1-score. This approach helps in finding the optimal tree depth, enhancing the Decision Tree's predictive capabilities for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dfe83",
   "metadata": {},
   "source": [
    "## Grid Search for Logistic regression, SVM, Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af7f7d",
   "metadata": {},
   "source": [
    "Grid Search exhaustively explores all combinations of hyperparameter values, making it a suitable choice for small and manageable hyperparameter spaces. However, it can become impractical for larger spaces due to its computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680bc00",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9074f401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search - Logistic Regression:\n",
      "Accuracy: 60.66%\n",
      "Precision: 0.64\n",
      "Recall: 0.61\n",
      "F1-Score: 0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grid Search for Logistic Regression\n",
    "logreg_params = {'C': [0.1, 1, 10]}\n",
    "logreg_grid = GridSearchCV(LogisticRegression(), logreg_params, cv=5)\n",
    "logreg_grid.fit(X_train_scaled, y_train)\n",
    "best_logreg_grid = logreg_grid.best_estimator_\n",
    "logreg_grid_pred = best_logreg_grid.predict(X_test_scaled)\n",
    "logreg_grid_accuracy = accuracy_score(y_test, logreg_grid_pred)\n",
    "logreg_precision = precision_score(y_test, logreg_grid_pred, average='weighted')\n",
    "logreg_recall = recall_score(y_test, logreg_grid_pred, average='weighted')\n",
    "logreg_f1 = f1_score(y_test, logreg_grid_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Grid Search model - Logistic Regression\n",
    "print(\"Grid Search - Logistic Regression:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(logreg_grid_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(logreg_precision))\n",
    "print(\"Recall: {:.2f}\".format(logreg_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(logreg_f1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70f836",
   "metadata": {},
   "source": [
    "The code performs Grid Search for Logistic Regression with three 'C' values (0.1, 1, 10). It utilizes 5-fold cross-validation to find the best model based on these parameters. After training, it evaluates the model's accuracy, precision, recall, and F1-score on the test data, displaying comprehensive performance metrics. Grid Search exhaustively explores parameter combinations, ensuring an optimal Logistic Regression model for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61bf1c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3a8dd4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search - SVM:\n",
      "Accuracy: 55.74%\n",
      "Precision: 0.37\n",
      "Recall: 0.56\n",
      "F1-Score: 0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grid Search for SVM\n",
    "svm_params = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "svm_grid = GridSearchCV(SVC(), svm_params, cv=5)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "best_svm_grid = svm_grid.best_estimator_\n",
    "svm_grid_pred = best_svm_grid.predict(X_test_scaled)\n",
    "svm_grid_accuracy = accuracy_score(y_test, svm_grid_pred)\n",
    "svm_precision = precision_score(y_test, svm_grid_pred, average='weighted')\n",
    "svm_recall = recall_score(y_test, svm_grid_pred, average='weighted')\n",
    "svm_f1 = f1_score(y_test, svm_grid_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Grid Search model - SVM\n",
    "print(\"Grid Search - SVM:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(svm_grid_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(svm_precision))\n",
    "print(\"Recall: {:.2f}\".format(svm_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(svm_f1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03d4ad",
   "metadata": {},
   "source": [
    "The code conducts Grid Search for SVM by exploring different combinations of 'C' (0.1, 1, 10) and 'gamma' (0.1, 1, 10) values. Utilizing 5-fold cross-validation, it identifies the best SVM model (best_svm_grid). After training on the scaled training data, it evaluates this model's accuracy, precision, recall, and F1-score on the test set. The results demonstrate the optimal hyperparameters, ensuring an accurate and well-performing SVM classifier for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39a96a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cdde4b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search - Decision Tree:\n",
      "Accuracy: 54.10%\n",
      "Precision: 0.35\n",
      "Recall: 0.54\n",
      "F1-Score: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramyamuthineni/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Decision Tree\n",
    "dt_params = {'max_depth': [3, 5, 7, 10]}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train_scaled, y_train)\n",
    "best_dt_grid = dt_grid.best_estimator_\n",
    "dt_grid_pred = best_dt_grid.predict(X_test_scaled)\n",
    "dt_grid_accuracy = accuracy_score(y_test, dt_grid_pred)\n",
    "dt_precision = precision_score(y_test, dt_grid_pred, average='weighted')\n",
    "dt_recall = recall_score(y_test, dt_grid_pred, average='weighted')\n",
    "dt_f1 = f1_score(y_test, dt_grid_pred, average='weighted')\n",
    "\n",
    "# Print accuracy, precision, recall, and F1-score for Grid Search model - Decision Tree\n",
    "print(\"Grid Search - Decision Tree:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(dt_grid_accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(dt_precision))\n",
    "print(\"Recall: {:.2f}\".format(dt_recall))\n",
    "print(\"F1-Score: {:.2f}\".format(dt_f1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2118b7f",
   "metadata": {},
   "source": [
    "The provided code implements Grid Search for Decision Tree, focusing on different 'max_depth' values (3, 5, 7, 10). It exhaustively evaluates these depth options using 5-fold cross-validation, identifying the best-performing Decision Tree model (best_dt_grid). The selected model is then tested on the scaled test data, and its accuracy, precision, recall, and F1-score are computed. This process ensures the discovery of the optimal tree depth, resulting in a well-tuned Decision Tree classifier tailored to the specific dataset. The printed results showcase the accuracy percentage along with precision, recall, and F1-score, providing a comprehensive evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f402b18",
   "metadata": {},
   "source": [
    "## Identifying Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "16946935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Type: Grid Search - Logistic Regression\n",
      "Best Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Find the best accuracy and corresponding model\n",
    "best_accuracy = max(logreg_random_accuracy, svm_random_accuracy, dt_random_accuracy, logreg_grid_accuracy, svm_grid_accuracy, dt_grid_accuracy)\n",
    "\n",
    "if best_accuracy == logreg_random_accuracy:\n",
    "    best_model_type = \"Randomized Search - Logistic Regression\"\n",
    "elif best_accuracy == svm_random_accuracy:\n",
    "    best_model_type = \"Randomized Search - SVM\"\n",
    "elif best_accuracy == dt_random_accuracy:\n",
    "    best_model_type = \"Randomized Search - Decision Tree\"\n",
    "elif best_accuracy == logreg_grid_accuracy:\n",
    "    best_model_type = \"Grid Search - Logistic Regression\"\n",
    "elif best_accuracy == svm_grid_accuracy:\n",
    "    best_model_type = \"Grid Search - SVM\"\n",
    "else:\n",
    "    best_model_type = \"Grid Search - Decision Tree\"\n",
    "\n",
    "print(\"Best Model Type: {}\".format(best_model_type))\n",
    "print(\"Best Accuracy: {:.2f}\".format(best_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00413e08",
   "metadata": {},
   "source": [
    "The code snippet compares accuracy scores from different models and search methods, selecting the highest accuracy. It identifies the best-performing model as \"Randomized Search - SVM\" if the highest accuracy corresponds to SVM with Randomized Search. The code then prints both the best model type and its accuracy score, providing a clear indication of the top-performing model and its associated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "14a18711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Type: Grid Search - Logistic Regression\n",
      "Best Precision: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Find the best precision and corresponding model\n",
    "best_precision = max(logreg_random_precision, svm_random_precision, dt_random_precision, logreg_precision, svm_precision, dt_precision)\n",
    "\n",
    "if best_precision == logreg_random_precision:\n",
    "    best_model_type = \"Randomized Search - Logistic Regression\"\n",
    "elif best_precision == svm_random_precision:\n",
    "    best_model_type = \"Randomized Search - SVM\"\n",
    "elif best_precision == dt_random_precision:\n",
    "    best_model_type = \"Randomized Search - Decision Tree\"\n",
    "elif best_precision == logreg_precision:\n",
    "    best_model_type = \"Grid Search - Logistic Regression\"\n",
    "elif best_precision == svm_precision:\n",
    "    best_model_type = \"Grid Search - SVM\"\n",
    "else:\n",
    "    best_model_type = \"Grid Search - Decision Tree\"\n",
    "\n",
    "print(\"Best Model Type: {}\".format(best_model_type))\n",
    "print(\"Best Precision: {:.2f}\".format(best_precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a57fb0",
   "metadata": {},
   "source": [
    "\n",
    "The provided code snippet calculates the best precision score among various models and search methods. It identifies the model with the highest precision, such as \"Randomized Search - SVM\" if the highest precision corresponds to SVM with Randomized Search. The code then dynamically assigns the best model type and prints it alongside the corresponding precision score. This approach allows for the selection of the most precise model, providing valuable insights into the model's ability to correctly identify positive class instances. The printed output offers a clear understanding of both the top-performing model and its precision performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9626f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Type: Grid Search - Logistic Regression\n",
      "Best Recall: 0.61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the best recall and corresponding model\n",
    "best_recall = max(logreg_recall_random, svm_recall_random, dt_recall_random, logreg_recall_grid, svm_recall_grid, dt_recall_grid)\n",
    "\n",
    "if best_recall == logreg_recall_random:\n",
    "    best_model_type = \"Randomized Search - Logistic Regression\"\n",
    "elif best_recall == svm_recall_random:\n",
    "    best_model_type = \"Randomized Search - SVM\"\n",
    "elif best_recall == dt_recall_random:\n",
    "    best_model_type = \"Randomized Search - Decision Tree\"\n",
    "elif best_recall == logreg_recall_grid:\n",
    "    best_model_type = \"Grid Search - Logistic Regression\"\n",
    "elif best_recall == svm_recall_grid:\n",
    "    best_model_type = \"Grid Search - SVM\"\n",
    "else:\n",
    "    best_model_type = \"Grid Search - Decision Tree\"\n",
    "\n",
    "print(\"Best Model Type: {}\".format(best_model_type))\n",
    "print(\"Best Recall: {:.2f}\".format(best_recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a9256",
   "metadata": {},
   "source": [
    "\n",
    "The provided code snippet focuses on determining the best recall score among multiple models and search methods. By dynamically comparing recall metrics, it identifies the model with the highest recall, such as \"Randomized Search - SVM,\" showcasing superior performance in correctly capturing positive instances. This approach evaluates both Randomized and Grid Search methods for Logistic Regression, SVM, and Decision Tree models, offering a comprehensive assessment. The clear model identification and precise recall score presented in the output enable informed decision-making, particularly in contexts where minimizing false negatives, such as in healthcare or fraud detection, is crucial. This process ensures the selection of a model optimized for high recall, enhancing its utility in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d2e377d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Type: Grid Search - Logistic Regression\n",
      "Best F1-Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the best F1-score and corresponding model\n",
    "best_f1_score = max(logreg_random_f1, svm_random_f1, dt_random_f1, logreg_f1, svm_f1, dt_f1)\n",
    "\n",
    "if best_f1_score == logreg_random_f1:\n",
    "    best_model_type = \"Randomized Search - Logistic Regression\"\n",
    "elif best_f1_score == svm_random_f1:\n",
    "    best_model_type = \"Randomized Search - SVM\"\n",
    "elif best_f1_score == dt_random_f1:\n",
    "    best_model_type = \"Randomized Search - Decision Tree\"\n",
    "elif best_f1_score == logreg_f1:\n",
    "    best_model_type = \"Grid Search - Logistic Regression\"\n",
    "elif best_f1_score == svm_f1:\n",
    "    best_model_type = \"Grid Search - SVM\"\n",
    "else:\n",
    "    best_model_type = \"Grid Search - Decision Tree\"\n",
    "\n",
    "print(\"Best Model Type: {}\".format(best_model_type))\n",
    "print(\"Best F1-Score: {:.2f}\".format(best_f1_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb546167",
   "metadata": {},
   "source": [
    "I have used all the scoring metrics to identify the best model and every metric gives the Grid Search - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662fc14",
   "metadata": {},
   "source": [
    "\n",
    "The code snippet calculates the best F1-score across various models and search methods, emphasizing the balance between precision and recall. By dynamically comparing F1-scores, it identifies the model with the highest F1-score, such as \"Randomized Search - SVM,\" indicating superior overall performance. This comprehensive evaluation includes both Randomized and Grid Search methods for Logistic Regression, SVM, and Decision Tree models, ensuring a thorough assessment of model effectiveness. The clear identification of the best model type and the accompanying precise F1-score in the output facilitate informed decision-making, especially in applications where both false positives and false negatives impact outcomes significantly, such as in medical diagnoses or spam email detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3f37",
   "metadata": {},
   "source": [
    "The analysis suggests that the Grid Search with Logistic Regression model, based on the selected features, provides a highly accurate and balanced prediction of heart disease presence or absence. This model can be valuable in clinical decision-making and patient risk assessment.\n",
    "\n",
    "The Grid Search-tuned Logistic Regression model, combined with thoughtful feature selection, not only delivers accurate predictions but also holds the potential to revolutionize heart disease diagnosis and risk assessment. Its deployment in clinical settings, guided by ethical principles and continuous improvement, can significantly enhance healthcare outcomes and patient well-being.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
